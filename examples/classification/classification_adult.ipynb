{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f6005c-1e82-45cc-9013-fa89752acadf",
   "metadata": {
    "id": "e4f6005c-1e82-45cc-9013-fa89752acadf"
   },
   "source": [
    "# Classification using Cyclic Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee82ebe-8aa4-49ee-a84b-2a9aed8868c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q8nS3cek3utK",
    "outputId": "e7b226b6-9dc5-4896-8066-8d105725fdd0"
   },
   "source": [
    "First, install the  package and its dependencies\n",
    "\n",
    "```sh\n",
    "!pip install cyclic-boosting\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0925b449-29d9-4ecc-aa65-bdc6da4b9627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optional formatting if juypter-black is installed\n",
    "try:\n",
    "    import jupyter_black\n",
    "\n",
    "    jupyter_black.load()\n",
    "except ImportError:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d032f099-abc3-414f-957d-bf915cd2bd4e",
   "metadata": {
    "id": "d032f099-abc3-414f-957d-bf915cd2bd4e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from cyclic_boosting import flags, common_smoothers, observers, binning\n",
    "from cyclic_boosting.plots import plot_analysis\n",
    "from cyclic_boosting.pipelines import pipeline_CBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f795a87a-df58-4b1a-8717-b95203fd65cd",
   "metadata": {},
   "source": [
    "Let's load the adult census income dataset from OpenML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c39b738-890f-45d0-b015-cc0a2306dc24",
   "metadata": {
    "id": "7c39b738-890f-45d0-b015-cc0a2306dc24",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "data = fetch_openml(data_id=1590)\n",
    "\n",
    "\n",
    "# Read the DataFrame, first using the feature data\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)  # Add a target column, and fill it with the target data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d07093-9357-422d-b982-65bc993834e4",
   "metadata": {},
   "source": [
    "For convenience we split the colums into two groups, categorical and continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G2BHuKj8Z4vM",
   "metadata": {
    "id": "G2BHuKj8Z4vM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_categorical = [\n",
    "    \"workclass\",\n",
    "    \"education\",\n",
    "    \"marital-status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"native-country\",\n",
    "]\n",
    "cols_noncat = [n for n in df.columns if n not in cols_categorical]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ce963a-fb5b-427f-902e-91da9568143a",
   "metadata": {},
   "source": [
    "Adding the target column to the dataframe and convert to 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2MnioVdq2O",
   "metadata": {
    "id": "3a2MnioVdq2O",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"target\"] = data.target.eq(\">50K\").mul(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hbvUSx1OPgKm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbvUSx1OPgKm",
    "outputId": "f2fa1a7c-2fde-4e06-e6a4-ab03fae246b0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_noncat + cols_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa7c80f-3979-4b6e-936d-5c29addcc31f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9fa7c80f-3979-4b6e-936d-5c29addcc31f",
    "outputId": "6c508533-441d-40c6-c9a3-a48b27ad8ce9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24974f7-4bb3-4d4c-912e-e90aa7884b16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert set(cols_noncat + cols_categorical) - set(df.columns) == set(), \"Columns not in data set\"\n",
    "print(\"unused columns:\", set(df.columns) - set(cols_noncat + cols_categorical))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4a3afc-c241-40c2-aaa7-5242b1c064f1",
   "metadata": {},
   "source": [
    "# Prepare the data\n",
    "\n",
    "The data has to be prepared for the training. We want to convert the categorical variables into numerical values using the scikit-learn OrdinalEncoder (guess, who contributed this ðŸ˜œ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d24d9c-01b5-4d01-9147-a6460f9d7f96",
   "metadata": {
    "id": "27d24d9c-01b5-4d01-9147-a6460f9d7f96",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    enc = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=np.nan)\n",
    "\n",
    "    df[cols_categorical] = enc.fit_transform(df[cols_categorical])\n",
    "\n",
    "    y = np.asarray(df[\"target\"])\n",
    "    X = df.drop(columns=\"target\")\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751aea1d-d1a3-421b-bd20-128d45f1d2ba",
   "metadata": {
    "id": "751aea1d-d1a3-421b-bd20-128d45f1d2ba",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = prepare_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36febea9-9a96-49e2-bae6-4ba934aa4343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a45753-d0eb-4e26-8ceb-01c8df2a64a1",
   "metadata": {},
   "source": [
    "# Set the feature properties\n",
    "\n",
    "We need to tell Cyclic Boosting which feature to use and what type of feature these are and how to handle them.\n",
    "\n",
    "We want the continuous features be `IS_CONTINUOUS` with missing values (very handy, isn't it ðŸ˜Ž) and the categorical features to be treated as unordered classes (no neighboring relation as in weekdays for example).\n",
    "\n",
    "Note: there is next to no feature engineering done here deliberately. Checking the feature carefully, there can be potentially improved a lot by treating the features individually and maybe even combing them into 2D features (see documentation). We just want to get it up-and-running here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1af2c74-91c0-40ef-85c7-51176966815f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = cols_categorical + cols_noncat\n",
    "\n",
    "feature_properties = {\n",
    "    **{col: flags.IS_UNORDERED | flags.HAS_MISSING | flags.MISSING_NOT_LEARNED for col in cols_categorical},\n",
    "    **{col: flags.IS_CONTINUOUS | flags.HAS_MISSING | flags.MISSING_NOT_LEARNED for col in cols_noncat},\n",
    "}\n",
    "features, feature_properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f888d5b-3134-48d7-8c9e-d7247f1d7b32",
   "metadata": {},
   "source": [
    "# Build the model\n",
    "\n",
    "The model is implemented as a scikit-learn pipeline, stitching together a Binner and the CB classifier estimator. Most natably, we reduce the number of used bins in all continuous features to 10 instead of 100, should be plenty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc5b45f-83e5-4bde-898b-48efcdcaf3f0",
   "metadata": {
    "id": "2fc5b45f-83e5-4bde-898b-48efcdcaf3f0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cb_classifier_model():\n",
    "    plobs = [observers.PlottingObserver(iteration=-1)]\n",
    "\n",
    "    CB_pipeline = pipeline_CBClassifier(\n",
    "        feature_properties=feature_properties,\n",
    "        feature_groups=features,\n",
    "        observers=plobs,\n",
    "        maximal_iterations=50,\n",
    "        number_of_bins=10,\n",
    "        smoother_choice=common_smoothers.SmootherChoiceGroupBy(\n",
    "            use_regression_type=True,\n",
    "            use_normalization=False,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return CB_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5b7bed-68c3-4470-9fd9-eefadefc0402",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "_S857kszB2N0",
    "outputId": "890d3b81-11e9-46b9-ec83-703a4f3c7db7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "CB_est = cb_classifier_model()\n",
    "\n",
    "CB_est"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1697b1-2eb8-4601-9d44-dc9b97bbdaa4",
   "metadata": {},
   "source": [
    "# The training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4951d71a-2696-41f6-9746-3e46ecc56703",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c802821e-3973-42be-83dc-50e9337b2210",
    "outputId": "77429d43-4b83-40ae-9fd8-04bbd2595711",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit -r 1\n",
    "CB_est.fit(X.copy(), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1edccbe-f17e-45ff-a277-da2da71031af",
   "metadata": {},
   "source": [
    "That's it, now we did the training, that was fast and easy, isn't it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782eac60-37c4-45ed-885e-eb1fc59d2166",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Now we can do the inference for all samples. Note that we get proper probabilities for all target categories using predict_proba, which is really nice! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154b2983-7d78-4ce1-aac8-3cf0f350cff4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c802821e-3973-42be-83dc-50e9337b2210",
    "outputId": "77429d43-4b83-40ae-9fd8-04bbd2595711",
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat = CB_est.predict_proba(X.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e772969e-1f89-4155-a232-d52cd5e337df",
   "metadata": {},
   "source": [
    "With this we can calculate the mean absolute deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031d7c9f-280d-4e1e-a363-1b8ecfa090a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c802821e-3973-42be-83dc-50e9337b2210",
    "outputId": "77429d43-4b83-40ae-9fd8-04bbd2595711",
    "tags": []
   },
   "outputs": [],
   "source": [
    "mad = np.nanmean(np.abs(y - yhat[:, 0]))\n",
    "mad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366682eb-dd77-4752-a98d-c9cd1ea7ea82",
   "metadata": {},
   "source": [
    "Or the scikit-learn in-sample score (yes, you should do some cross-validation for a real world problem ðŸ˜¬)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6GJY01vLR-G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6GJY01vLR-G",
    "outputId": "1ee5400f-e44d-4e93-a140-d0d6cfb35c47",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# in-sample score\n",
    "CB_est.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec052aa-622a-431e-8874-bff6de8c5124",
   "metadata": {},
   "source": [
    "# Some nice plots\n",
    "\n",
    "Cyclic Boosting has some useful reporting of the traning included. We can create a pdf with this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145d75e4-aabe-4f7a-89fc-12d4df8c72e8",
   "metadata": {
    "id": "145d75e4-aabe-4f7a-89fc-12d4df8c72e8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_CB(filename, plobs, binner):\n",
    "    for i, p in enumerate(plobs):\n",
    "        plot_analysis(plot_observer=p, file_obj=filename + \"_{}\".format(i), use_tightlayout=False, binners=[binner])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bd7d19-4320-4666-9554-99587b1dc63e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c802821e-3973-42be-83dc-50e9337b2210",
    "outputId": "77429d43-4b83-40ae-9fd8-04bbd2595711",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_CB(\"analysis_CB_iterlast\", [CB_est[-1].observers[-1]], CB_est[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b354090a-4dc7-4c7d-aaba-8d4bf0e76fde",
   "metadata": {},
   "source": [
    "You will now find a pdf file containing all sorts of plots. They are explained in the documentation of Cyclic Boosting.\n",
    "\n",
    "Just as an eye candy, lets plot the separation of of both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0bac85-270f-4b69-baaa-eb6379840c74",
   "metadata": {
    "id": "9e0bac85-270f-4b69-baaa-eb6379840c74",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"pred\"] = yhat[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xb2OubdTFTik",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "xb2OubdTFTik",
    "outputId": "71e5a437-68a8-4b3b-c960-8570331e286e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = df[df[\"target\"] > 0].pred.hist(log=True, alpha=0.5)\n",
    "df[df[\"target\"] == 0].pred.hist(log=True, alpha=0.5, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06332047-674e-4fc2-9f7a-fefe8137652f",
   "metadata": {
    "id": "f65d33f1-bb4f-41f3-9491-6f2add0a8ac8"
   },
   "source": [
    "You see, it is easy to do a classification using Cyclic Boosting and it works!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
