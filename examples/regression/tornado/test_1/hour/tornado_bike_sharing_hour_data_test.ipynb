{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f6005c-1e82-45cc-9013-fa89752acadf",
   "metadata": {
    "id": "e4f6005c-1e82-45cc-9013-fa89752acadf"
   },
   "source": [
    "# Regression using Cyclic Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee82ebe-8aa4-49ee-a84b-2a9aed8868c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q8nS3cek3utK",
    "outputId": "e7b226b6-9dc5-4896-8066-8d105725fdd0"
   },
   "source": [
    "First, install the  package and its dependencies\n",
    "\n",
    "```sh\n",
    "!pip install cyclic-boosting\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d032f099-abc3-414f-957d-bf915cd2bd4e",
   "metadata": {
    "id": "d032f099-abc3-414f-957d-bf915cd2bd4e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's use the test dataset from kaggle\n",
    "\n",
    "Sign in to Kaggle at the URL below and download the dataset.  \n",
    "https://www.kaggle.com/datasets/lakshmi25npathi/bike-sharing-dataset\n",
    "\n",
    "Place the downloaded dataset in the following directory.  \n",
    "examples/regression/tornado/test_1/bike_sharing_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f795a87a-df58-4b1a-8717-b95203fd65cd",
   "metadata": {},
   "source": [
    "For time-series data, a \"date\" column must be included to indicate the date and time the data was obtained. The column name and format must be consistent. The \"dayofweek\" column for the day of the week and the \"dayofyear\" column for the total number of days in the year are automatically created if not already present, but if they are already present, the column names must be correct.\n",
    "\n",
    "This dataset has hourly data. In this dataset, the \"instant\" column is the data number. The \"casual\" and \"registered\" columns are the breakdown of sales, so they should be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c39b738-890f-45d0-b015-cc0a2306dc24",
   "metadata": {
    "id": "7c39b738-890f-45d0-b015-cc0a2306dc24",
    "tags": []
   },
   "outputs": [],
   "source": [
    "parpath = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "df = pd.read_csv(parpath + \"/bike_sharing_data/hour.csv\")\n",
    "df = df.rename(columns={'dteday': 'date', 'weekday': 'dayofweek'})\n",
    "df = df.drop(columns=['instant', 'casual', 'registered'])\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df['date'] = df['date'] + df['hr'].map(lambda x: datetime.timedelta(hours=float(x)))\n",
    "\n",
    "df.to_csv(\"./bike_sharing_hour.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8692944-7695-4823-82ef-fb2a22a399a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1220e50d",
   "metadata": {},
   "source": [
    "# Automated Machine Learning with Tornado\n",
    "With tornado, you can automatically perform data preparation, feature property setting, hyperparameter tuning, model building, training, evaluation, and plotting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccbe9343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cyclic_boosting.tornado import Generator, Manager, Trainer\n",
    "\n",
    "data_deliverler = Generator.TornadoDataModule(\"./bike_sharing_hour.csv\")\n",
    "manager = Manager.TornadoVariableSelectionModule()\n",
    "trainer = Trainer.SqueezeTrainer(data_deliverler, manager)\n",
    "trainer.run(target=\"cnt\", log_policy=\"compute_COD\", verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15833e8f",
   "metadata": {},
   "source": [
    "# Load the best model and make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ea2396",
   "metadata": {},
   "source": [
    "Get the best model path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d0ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "model_nos = []\n",
    "for p in sorted(Path(\"./models/\").glob(\"model*\")):\n",
    "    model_nos.append(str(p)[str(p).find(\"_\") + 1 :])\n",
    "model_path = f\"./models/model_{model_nos[-1]}/model_{model_nos[-1]}.pkl\"\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67a0e00",
   "metadata": {},
   "source": [
    "Make predictions with the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6cf4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'season': [4],\n",
    "    'yr': [0],\n",
    "    'mnth': [11],\n",
    "    'hr': [18],\n",
    "    'holiday': [0],\n",
    "    'workingday': [1],\n",
    "    'weathersit': [2],\n",
    "    'temp': [0.341667],\n",
    "    'atemp': [0.323221],\n",
    "    'hum': [0.575833],\n",
    "    'windspeed': [0.305362],\n",
    "    'dayofweek': [4],\n",
    "    'dayofyear': [180],\n",
    "}\n",
    "X = pd.DataFrame(data)\n",
    "\n",
    "with open(model_path, \"rb\") as f:\n",
    "    CB_est = pickle.load(f)\n",
    "    yhat = CB_est.predict(X.copy())\n",
    "    print(yhat)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
